{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPq9rjWUWXHMukt3Og4+K03",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumitKaware/book-recommender/blob/main/BookRecommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oocrO2xD7tMM"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_community langchain_huggingface langchain_chroma gradio tf_keras"
      ],
      "metadata": {
        "id": "dQhWTWnhWB2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade numpy"
      ],
      "metadata": {
        "id": "Roy6qoREZ_WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#from dotenv import load_dotenv\n",
        "import io\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "#from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "#load_dotenv()\n",
        "\n",
        "# Load dataset\n",
        "books = pd.read_csv(\"books_with_emotions.csv\")\n",
        "print(books.shape)\n",
        "books[\"large_thumbnail\"] = books[\"thumbnail\"] + \"&file=w800\"\n",
        "#books[\"large_thumbnail\"].fillna(\"cover-not-found.jpg\", inplace=True)\n",
        "books[\"large_thumbnail\"] = np.where(\n",
        "    books[\"large_thumbnail\"].isna(),\n",
        "    \"cover-not-found.jpg\",\n",
        "    books[\"large_thumbnail\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "KDTx_Xl5VJdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "ATBWlaTeas__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#raw_documents = TextLoader(io.BytesIO(uploaded[\"tagged_description.txt\"])).load()\n",
        "raw_documents = TextLoader(\"tagged_description.txt\").load()\n",
        "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=0, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "#db_books = Chroma.from_documents(documents, HuggingFaceEmbeddings())\n"
      ],
      "metadata": {
        "id": "wrDKncwrV6XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tf_keras as keras\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "db_books = Chroma.from_documents(\n",
        "    documents,\n",
        "    embedding=embeddings\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "AYQfpSk6dR93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def retrieve_semantic_recommendations(\n",
        "        query: str,\n",
        "        category: str = None,\n",
        "        tone: str = None,\n",
        "        initial_top_k: int = 50,\n",
        "        final_top_k: int = 16,\n",
        ") -> pd.DataFrame:\n",
        "\n",
        "    recs = db_books.similarity_search(query, k=initial_top_k)\n",
        "    books_list = [int(rec.page_content.strip('\"').split()[0]) for rec in recs]\n",
        "    book_recs = books[books[\"isbn13\"].isin(books_list)].head(initial_top_k)\n",
        "\n",
        "    if category != \"All\":\n",
        "        book_recs = book_recs[book_recs[\"simple_categories\"] == category].head(final_top_k)\n",
        "    else:\n",
        "        book_recs = book_recs.head(final_top_k)\n",
        "\n",
        "    if tone == \"Happy\":\n",
        "        book_recs.sort_values(by=\"joy\", ascending=False, inplace=True)\n",
        "    elif tone == \"Surprising\":\n",
        "        book_recs.sort_values(by=\"surprise\", ascending=False, inplace=True)\n",
        "    elif tone == \"Angry\":\n",
        "        book_recs.sort_values(by=\"anger\", ascending=False, inplace=True)\n",
        "    elif tone == \"Suspenseful\":\n",
        "        book_recs.sort_values(by=\"fear\", ascending=False, inplace=True)\n",
        "    elif tone == \"Sad\":\n",
        "        book_recs.sort_values(by=\"sadness\", ascending=False, inplace=True)\n",
        "\n",
        "    return book_recs\n",
        "\n",
        "\n",
        "def recommend_books(\n",
        "        query: str,\n",
        "        category: str,\n",
        "        tone: str\n",
        "):\n",
        "    recommendations = retrieve_semantic_recommendations(query, category, tone)\n",
        "    results = []\n",
        "\n",
        "    for _, row in recommendations.iterrows():\n",
        "        description = row[\"description\"]\n",
        "        truncated_desc_split = description.split()\n",
        "        truncated_description = \" \".join(truncated_desc_split[:30]) + \"...\"\n",
        "\n",
        "        authors_split = row[\"authors\"].split(\";\")\n",
        "        if len(authors_split) == 2:\n",
        "            authors_str = f\"{authors_split[0]} and {authors_split[1]}\"\n",
        "        elif len(authors_split) > 2:\n",
        "            authors_str = f\"{', '.join(authors_split[:-1])}, and {authors_split[-1]}\"\n",
        "        else:\n",
        "            authors_str = row[\"authors\"]\n",
        "\n",
        "        caption = f\"{row['title']} by {authors_str}: {truncated_description}\"\n",
        "        results.append((row[\"large_thumbnail\"], caption))\n",
        "    return results\n",
        "\n",
        "categories = [\"All\"] + sorted(books[\"simple_categories\"].unique())\n",
        "tones = [\"All\"] + [\"Happy\", \"Surprising\", \"Angry\", \"Suspenseful\", \"Sad\"]\n",
        "\n",
        "with gr.Blocks(theme = gr.themes.Glass()) as dashboard:\n",
        "    gr.Markdown(\"# Semantic book recommender\")\n",
        "\n",
        "    with gr.Row():\n",
        "        user_query = gr.Textbox(label = \"Please enter a description of a book:\",\n",
        "                                placeholder = \"e.g., A story about forgiveness\")\n",
        "        category_dropdown = gr.Dropdown(choices = categories, label = \"Select a category:\", value = \"All\")\n",
        "        tone_dropdown = gr.Dropdown(choices = tones, label = \"Select an emotional tone:\", value = \"All\")\n",
        "        submit_button = gr.Button(\"Find recommendations\")\n",
        "\n",
        "    gr.Markdown(\"## Recommendations\")\n",
        "    output = gr.Gallery(label = \"Recommended books\", columns = 8, rows = 2)\n",
        "\n",
        "    submit_button.click(fn = recommend_books,\n",
        "                        inputs = [user_query, category_dropdown, tone_dropdown],\n",
        "                        outputs = output)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dashboard.launch()"
      ],
      "metadata": {
        "id": "8pNoCcv-aq9h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}